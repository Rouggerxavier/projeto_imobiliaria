PORT=8000
LOG_LEVEL=info

# === LLM CONFIG ===
# Prioridade: Google Gemini (OpenAI compat) > OpenAI/OpenRouter > Groq/Ollama

# Google Gemini via endpoint compatível com OpenAI
OPENAI_API_KEY=AIzaSyA-qIbDTMkEQn8kv6ubHR7DOKEeM7J_9Wo
OPENAI_MODEL=models/gemini-2.0-flash
OPENAI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai


# LLM habilitado? (true=usa LLM, false=só fallback)
USE_LLM=false

# Timeout da chamada LLM (segundos). Aumente para LLM local em CPU.
LLM_TIMEOUT=120

# === LLM LOCAL (Ollama) ===
# Mantem o modelo carregado apos chamadas (ex.: 30m).
LLM_KEEP_ALIVE=30m
# Contexto menor = menos RAM e mais velocidade.
LLM_NUM_CTX=2048
# Use mais threads da CPU (ajuste conforme sua maquina).
LLM_NUM_THREADS=8
# mmap ajuda a reduzir pico de RAM (Windows pode variar).
LLM_USE_MMAP=true
# Faz pre-warm no startup para evitar cold start na 1a requisicao.
LLM_PREWARM=true

WHATSAPP_VERIFY_TOKEN=rougg1327
WHATSAPP_PHONE_NUMBER_ID=    
ID_CONTA_WPP_BUSINESS=
WHATSAPP_ACCESS_TOKEN=

# Modo apenas triagem (sem busca/listagem de imóveis)
TRIAGE_ONLY=true
